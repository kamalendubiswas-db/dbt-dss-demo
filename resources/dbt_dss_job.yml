resources:
  jobs:
    dbt_dss_job:
      name: dbt_dss_job
      tasks:
        - task_key: dbt_dss_job
          dbt_task:
            project_directory: ${workspace.file_path}/
            commands:
              - dbt deps #If you have private packages this can be run before bundle deploy
              - "dbt build --exclude tag:stream --vars 'schema_prefix: ${var.schema_prefix}'" # Remove exclude if you want to run with streaming tables
            warehouse_id: ${var.warehouse_id} 
            catalog: ${var.dbt_catalog}
            source: WORKSPACE
          job_cluster_key: dbt_CLI
          libraries:
            - pypi:
                package: dbt-databricks>=1.0.0,<2.0.0
      job_clusters:
        - job_cluster_key: dbt_CLI
          new_cluster:
            spark_version: 13.3.x-scala2.12
            spark_conf:
              spark.master: local[*, 4]
              spark.databricks.cluster.profile: singleNode
            azure_attributes:
              first_on_demand: 1
              availability: ON_DEMAND_AZURE
              spot_bid_max_price: -1
            node_type_id: Standard_DS3_v2
            custom_tags:
              ResourceClass: SingleNode
            spark_env_vars:
              PYSPARK_PYTHON: /databricks/python3/bin/python3
            enable_elastic_disk: true
            data_security_mode: SINGLE_USER
            runtime_engine: PHOTON
            num_workers: 0
